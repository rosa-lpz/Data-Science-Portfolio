{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "459f7a6d-6da9-462a-832b-5c604685ced7",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b886d760-a42b-4994-8b5b-4ff9bd2c49c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dad6ef-813a-479b-91f8-ba4f94b296fd",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3111ae5-7afc-48a8-a64e-2b7842415e71",
   "metadata": {},
   "source": [
    "## Get data and create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18a0e61c-ea8a-4a94-9261-ace2926cd565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFrames(files_names, data_dir):\n",
    "    \"\"\"\n",
    "    Reads multiple CSV files and returns a list of DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "        file_name_pairs (list of tuples): Each tuple contains (file_name, df_name) — df_name is ignored here.\n",
    "        data_dir (str): Directory where the CSV files are stored.\n",
    "\n",
    "    Returns:\n",
    "        list: List of pandas DataFrames.\n",
    "    \"\"\"\n",
    "    dataframes = {}\n",
    "\n",
    "    for file_name, df_name in files_names:\n",
    "        try:\n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes[df_name] = df\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_name}: {e}\")\n",
    "\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e9c397-e92e-426c-b432-55ea7f3be1eb",
   "metadata": {},
   "source": [
    "## Show all DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf4b14f3-3883-4cee-9e64-0d68a35e75bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showDataFrame(files_names):\n",
    "    #Import and print data  \n",
    "    try:\n",
    "        # Loop through the files and read them\n",
    "        for file_name, df_name in files_names:\n",
    "            df = pd.read_csv(f\"{DATA_DIR}{file_name}\")\n",
    "            print(f\"{df_name} DataFrame \\n\")\n",
    "            display(df.head())\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(\"One or more CSV files not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda4721f-3606-4ceb-a44e-7b2ce2decfb3",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f376afa-3f35-407a-8853-f70be2ba3bd0",
   "metadata": {},
   "source": [
    "## Shape, data types, missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6733c1-6c6e-4dd1-8ff7-74f27d62f5b7",
   "metadata": {},
   "source": [
    "### Various dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f77026-75c6-499f-9cd8-14f2adea6f44",
   "metadata": {},
   "source": [
    "```python\n",
    "#Function to explore a list of dataframes\n",
    "def exploreDataFrames(dataframe_list,dataframe_names):\n",
    "    for i, df in enumerate(dataframe_list):\n",
    "        print(f\"DataFrame: {dataframe_names[i]}\")\n",
    "        print(\"\\nShape:\", df.shape,\"\\n\")\n",
    "        print(\"\\nData Types:\\n\", df.dtypes, \"\\n\")\n",
    "        # print(\"\\nDescriptive Statistics:\\n\", df.describe(include='all'), \"\\n\")\n",
    "        print(\"\\nMissing Values:\\n\", df.isnull().sum(), \"\\n\")\n",
    "        print(\"-\" * 70)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b37e7a3a-aff0-437e-b684-9213b9d61d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to explore a dictionary of dataframes\n",
    "def exploreDataFrames(dataframe_dict):\n",
    "    for name, df in dataframe_dict.items():\n",
    "        print(f\"\\nDataFrame: {name}\")\n",
    "        print(\"Shape:\", df.shape)\n",
    "        print(\"\\nData Types:\\n\", df.dtypes)\n",
    "        #print(\"\\nDescriptive Statistics:\\n\", df.describe(include='all'))\n",
    "        print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "        print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b636487b-32c0-4455-8e8c-d50daa812257",
   "metadata": {},
   "source": [
    "### Single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c60d49eb-498a-4988-aff3-879cec40d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to explore a single DataFrame\n",
    "def exploreDataFrame(df, df_name):\n",
    "    print(f\"\\nExploring DataFrame: {df_name}\\n\")\n",
    "    print(\"Shape:\", df.shape,\"\\n\")\n",
    "    print(\"Data Types:\\n\", df.dtypes, \"\\n\")\n",
    "    #print(\"\\nDescriptive Statistics:\\n\", df.describe(include='all'), \"\\n\")\n",
    "    print(\"Missing Values:\\n\", df.isnull().sum(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fd1d54-5f7a-481f-9bc4-322b5c26a617",
   "metadata": {},
   "source": [
    "### summarizeDataframe\n",
    "Python function that takes a pandas DataFrame as input and returns a new DataFrame summarizing the following information for each column:\n",
    "\n",
    "    Data Type\n",
    "\n",
    "    Number of Missing Values\n",
    "\n",
    "    Missing Values %\n",
    "\n",
    "    Minimum Value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50dc672e-8e95-43d7-af6b-7da305130d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import pandas as pd\n",
    "\n",
    "def summarizeDataFrame1(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    summary = pd.DataFrame(index=df.columns)\n",
    "    \n",
    "    summary['Data Type'] = df.dtypes\n",
    "    summary['Number of Missing Values'] = df.isnull().sum()\n",
    "    summary['Missing Values %'] = (df.isnull().mean() * 100).round(2)\n",
    "    \n",
    "    # Initialize min and max with None, to be conditionally filled\n",
    "    summary['Minimum Value'] = None\n",
    "    summary['Maximum Value'] = None\n",
    "\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            summary.at[col, 'Minimum Value'] = df[col].min()\n",
    "            summary.at[col, 'Maximum Value'] = df[col].max()\n",
    "\n",
    "    return summary\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f41a8c-86af-4cf5-80df-25c64efcbd8a",
   "metadata": {},
   "source": [
    "Order and naming format you specified:\n",
    "\n",
    "    Column Name\n",
    "    Data type\n",
    "    Count\n",
    "    Missing Values (#)\n",
    "    Missing Values (%)\n",
    "    Mean\n",
    "    STD\n",
    "    Min\n",
    "    25%\n",
    "    50%\n",
    "    75%\n",
    "    Max\n",
    "\n",
    "The function handles numeric columns for statistical calculations and returns None for non-numeric columns in those fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b054aa3a-2be3-4714-8c8c-9c1476c35e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeDataFrame(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    summary_data = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_data = df[col]\n",
    "        data_type = col_data.dtype\n",
    "        total_count = col_data.count()\n",
    "        missing_count = col_data.isnull().sum()\n",
    "        missing_percent = round((missing_count / len(df)) * 100, 2)\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(col_data):\n",
    "            mean = col_data.mean()\n",
    "            std = col_data.std()\n",
    "            min_val = col_data.min()\n",
    "            q25 = col_data.quantile(0.25)\n",
    "            q50 = col_data.quantile(0.50)\n",
    "            q75 = col_data.quantile(0.75)\n",
    "            max_val = col_data.max()\n",
    "        else:\n",
    "            mean = std = min_val = q25 = q50 = q75 = max_val = None\n",
    "\n",
    "        summary_data.append({\n",
    "            \"Column Name\": col,\n",
    "            \"Data type\": data_type,\n",
    "            \"Count\": total_count,\n",
    "            \"Missing Values (#)\": missing_count,\n",
    "            \"Missing Values (%)\": missing_percent,\n",
    "            \"Mean\": mean,\n",
    "            \"STD\": std,\n",
    "            \"Min\": min_val,\n",
    "            \"25%\": q25,\n",
    "            \"50%\": q50,\n",
    "            \"75%\": q75,\n",
    "            \"Max\": max_val\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    return summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeb92ca-ade6-4f0b-9235-5f1e78d3c77a",
   "metadata": {},
   "source": [
    "## Analyze features\n",
    "* Numerical features and descriptive statistics\n",
    "* Categorical features (counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46abff98-6f95-490f-84e0-03bc0eb3635e",
   "metadata": {},
   "source": [
    "### Various dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c43647b-8888-41a7-b3d1-e5af1430aab2",
   "metadata": {},
   "source": [
    "```python\n",
    "# Analyze features from a list of dataframes\n",
    "def analyzeDFsFeatures(dataframe_list,dataframe_names):\n",
    "    for i, df in enumerate(dataframe_list):\n",
    "        print(f\"DataFrame: {dataframe_names[i]}\")\n",
    "\n",
    "        # Analyze Numerical Features\n",
    "        numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "        if len(numerical_cols) > 0:\n",
    "            print(\"\\nNumerical Features:\")\n",
    "            print(df[numerical_cols].describe())\n",
    "        else:\n",
    "            print(\"\\nNo Numerical Features\")\n",
    "    \n",
    "        # Analyze Categorical Features\n",
    "        categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "        for col in categorical_cols:\n",
    "            print(f\"\\nCategorical Feature: {col}\")\n",
    "            print(df[col].value_counts())\n",
    "        print(\"-\" * 50)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f983e474-57cc-444f-a2cb-b76485805e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze features from a dictionary of dataframes\n",
    "def analyzeDFsFeatures(dataframe_dict):\n",
    "    for name, df in dataframe_dict.items():\n",
    "        print(f\"\\nDataFrame: {name}\\n\")\n",
    "        # Analyze Numerical Features\n",
    "        numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "        if len(numerical_cols) > 0:\n",
    "            print(\"\\nNumerical Features:\\n\")\n",
    "            print(df[numerical_cols].describe())\n",
    "        else:\n",
    "            print(\"\\nNo Numerical Features:\\n\")\n",
    "    \n",
    "        # Analyze Categorical Features\n",
    "        categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "        for col in categorical_cols:\n",
    "            print(f\"\\nCategorical Feature: {col}\")\n",
    "            print(df[col].value_counts())\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b44136-0dc8-4471-8584-a7c2da7b97ce",
   "metadata": {},
   "source": [
    "### Single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "13614e7c-2866-4f4c-9c59-998e600281fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze features from a single dataframe\n",
    "def analyzeDFFeatures(df,df_name):\n",
    "    print(f\"DataFrame: {df_name}\\n\")\n",
    "    \n",
    "    # Analyze Numerical Features\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "    if len(numerical_cols) > 0:\n",
    "        print(\"\\nNumerical Features:\\n\")\n",
    "        print(df[numerical_cols].describe())\n",
    "    else:\n",
    "        print(\"\\nNo Numerical Features:\\n\")\n",
    "\n",
    "    # Analyze Categorical Features\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        print(f\"\\nCategorical Feature: {col}\")\n",
    "        print(df[col].value_counts())\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6105996f-2028-489d-945f-9da607e91017",
   "metadata": {},
   "source": [
    "## Find outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35545e5b-abfb-4fc5-8a10-f2d5a4a14179",
   "metadata": {},
   "source": [
    "### Various dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c943973d-2189-45bb-85f9-7c6df3712c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find outliers in dictionary of DataFrames\n",
    "def findOutliersDFs(dataframe_dict):\n",
    "    for name, df in dataframe_dict.items():\n",
    "        print(f\"\\nDataFrame: {name}\\n\")\n",
    "        # Analyze Numerical Features\n",
    "        numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "        # Check for outliers in telemetry data using IQR\n",
    "        for col in numerical_cols:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "            print(f\"\\nPotential outliers in {col}:\\n\", outliers.shape[0])\n",
    "        print(\"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eafb38-7bad-4455-af9b-61bba6e74fe5",
   "metadata": {},
   "source": [
    "### Single Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c378a3f3-4f4d-4725-a898-5a8dcb57e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find outliers in a single DataFrame\n",
    "def findOutliersDF(df, df_name):\n",
    "    # Check for outliers in telemetry data using IQR\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "    for col in numerical_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        print(f\"\\nPotential outliers in {col}:\\n\", outliers.shape[0])\n",
    " \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4ebd25-5973-44a3-9914-23b32bb4bcaa",
   "metadata": {},
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ba1413-f2ef-4662-92d1-2fb059cf8a0e",
   "metadata": {},
   "source": [
    "### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "104cac0e-ec0d-4410-baa6-d0435859a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlibBoxplot(df,columns):\n",
    "    df[columns].plot(kind='box', figsize=(12, 8))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78ca78c9-9766-4122-90b9-64e7b732b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seabornBoxplot(df, columns):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(data=df[columns], orient='v', palette='Set2') # orient h (horizontal) v (vertical)\n",
    "    plt.title(\"Boxplot of Selected Columns\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a910aa-fd72-49f3-b271-9ef213e7efc2",
   "metadata": {},
   "source": [
    "### Check Distribution and Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da73c03-a18d-4278-a165-e7594b9db8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c5eb60-c3e3-46ef-a853-e2f79bd0299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#from scipy.stats import shapiro, normaltest, probplot\n",
    "\n",
    "def checkDataFrameNormality(df, alpha=0.05, show_plots=True, max_sample_size=5000):\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    results = []\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        data = df[col].dropna()\n",
    "\n",
    "        if len(data) < 8:\n",
    "            print(f\"⚠️ Skipping '{col}': Not enough non-null values (<8).\")\n",
    "            continue\n",
    "\n",
    "        \"\"\"Downsample large data for Shapiro (not reliable above 5000)\n",
    "        shapiro_sample = data.sample(min(len(data), max_sample_size), random_state=42)\n",
    "        try:\n",
    "            shapiro_p = shapiro(shapiro_sample).pvalue\n",
    "        except Exception:\n",
    "            shapiro_p = np.nan\"\"\"\n",
    "\n",
    "        # D’Agostino test (OK for large samples)\n",
    "        try:\n",
    "            dagostino_p = normaltest(data).pvalue\n",
    "        except Exception:\n",
    "            dagostino_p = np.nan\n",
    "\n",
    "        is_normal = (shapiro_p > alpha if not np.isnan(shapiro_p) else False) and \\\n",
    "                    (dagostino_p > alpha if not np.isnan(dagostino_p) else False)\n",
    "\n",
    "        results.append({\n",
    "            'Column': col,\n",
    "            'Non-Null Count': len(data),\n",
    "            'Shapiro p-value': round(shapiro_p, 4) if not np.isnan(shapiro_p) else 'n/a',\n",
    "            'D’Agostino p-value': round(dagostino_p, 4) if not np.isnan(dagostino_p) else 'n/a',\n",
    "            'Likely Normal?': '✅ Yes' if is_normal else '❌ No'\n",
    "        })\n",
    "\n",
    "        # Optional visualization\n",
    "        if show_plots:\n",
    "            print(f\"\\n📊 Analyzing: {col}\")\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "            # Histogram with KDE\n",
    "            sns.histplot(data, kde=True, ax=axes[0], color='skyblue')\n",
    "            axes[0].set_title(f\"{col} - Histogram + KDE\")\n",
    "\n",
    "            # Q-Q Plot\n",
    "            probplot(data, dist=\"norm\", plot=axes[1])\n",
    "            axes[1].set_title(f\"{col} - Q-Q Plot\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "    return result_df.sort_values(by='Likely Normal?', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd50b79e-5136-4584-b7b3-a785ebe28f6e",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cc6c02-3634-444a-97e6-383959aea0a0",
   "metadata": {},
   "source": [
    "### Line Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07118d8-8887-49e7-8d88-1bf6dac779c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9798544c-9b99-4507-a198-7dba0eb77d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15ef92c4-108c-42e9-b006-bdb7e1af3fbb",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336efc7a-416b-4b80-8275-1f20ae694d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da26ab5f-da36-4f27-802d-46964aa11855",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef05bb-c56c-4560-9e3d-77a20b9b503f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
